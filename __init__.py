import torch
import numpy as np
import io
import os
import sys
from PIL import Image

# å°è¯•å¯¼å…¥å®˜æ–¹åº“
try:
    from google import genai
    from google.genai import types
except ImportError:
    print("\nâŒ ç¼ºå°‘ google-genai åº“ï¼Œè¯·è¿è¡Œ pip install google-genai\n")
    genai = None
    types = None

# ==========================================
# æ ¸å¿ƒèŠ‚ç‚¹ç±»ï¼šå¤§é¦™è•‰Pro (éšç§ä¿æŠ¤ç‰ˆ)
# ==========================================
class BigBananaProNode:
    def __init__(self):
        self.current_dir = os.path.dirname(os.path.abspath(__file__))

    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                # 1. è¿™é‡Œç•™ç©ºï¼Œé»˜è®¤å»è¯»æ–‡ä»¶
                "APIå¯†é’¥": ("STRING", {"multiline": False, "default": "", "placeholder": "ç•™ç©ºåˆ™è‡ªåŠ¨è¯»å– api_key.txt"}),
                
                "æç¤ºè¯": ("STRING", {"multiline": True, "dynamicPrompts": True, "default": "A futuristic city with flying cars, cinematic lighting, 4k, masterpiece"}),
                
                # 2. æ”¹å›ä½ è¦çš„é»˜è®¤å€¼
                "æ¨¡å‹åç§°": ("STRING", {"multiline": False, "default": "gemini-3-pro-image-preview"}),
                
                "ç”»è´¨ç­‰çº§": (["1K", "2K", "4K"], {"default": "1K"}),
                "é•¿å®½æ¯”": (["1:1", "16:9", "9:16", "4:3", "3:4", "21:9", "5:4", "4:5", "æœªæŒ‡å®š(Free)"], {"default": "1:1"}),
                
                "å¯ç”¨Googleæœç´¢": ("BOOLEAN", {"default": False, "label_on": "å¼€å¯ (Grounding)", "label_off": "å…³é—­"}),
                "ä»£ç†åœ°å€": ("STRING", {"multiline": False, "default": "", "placeholder": "ä¾‹å¦‚ http://127.0.0.1:7890 (ç•™ç©ºè‡ªåŠ¨)"}),
            },
            "optional": {
                "å‚è€ƒå›¾": ("IMAGE",),
            }
        }

    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("å›¾åƒ",)
    FUNCTION = "generate_image"
    CATEGORY = "Banana"

    def tensor_to_bytes(self, img_tensor):
        i = 255. * img_tensor.cpu().numpy()
        img_pil = Image.fromarray(np.clip(i, 0, 255).astype(np.uint8))
        buffered = io.BytesIO()
        img_pil.save(buffered, format="JPEG", quality=95) 
        return buffered.getvalue()

    def get_api_key(self, input_key):
        """
        è·å– API Key çš„é€»è¾‘ï¼š
        1. ä¼˜å…ˆä½¿ç”¨èŠ‚ç‚¹è¾“å…¥æ¡†é‡Œçš„å†…å®¹ã€‚
        2. å¦‚æœè¾“å…¥æ¡†ä¸ºç©ºï¼Œå°è¯•è¯»å–æ’ä»¶ç›®å½•ä¸‹çš„ api_key.txtã€‚
        """
        # æƒ…å†µ1: ç”¨æˆ·åœ¨UIé‡Œå¡«äº†ï¼Œç›´æ¥ç”¨
        if input_key and input_key.strip():
            return input_key.strip()

        # æƒ…å†µ2: å°è¯•è¯»å–æ–‡ä»¶
        key_file = os.path.join(self.current_dir, "api_key.txt")
        if os.path.exists(key_file):
            try:
                with open(key_file, "r", encoding="utf-8") as f:
                    file_key = f.read().strip()
                    if file_key:
                        print("ğŸ”‘ å·²ä» api_key.txt è‡ªåŠ¨åŠ è½½å¯†é’¥", flush=True)
                        return file_key
            except Exception as e:
                print(f"âš ï¸ è¯»å– api_key.txt å¤±è´¥: {e}", flush=True)
        
        return None

    def generate_image(self, APIå¯†é’¥, æç¤ºè¯, æ¨¡å‹åç§°, ç”»è´¨ç­‰çº§, é•¿å®½æ¯”, å¯ç”¨Googleæœç´¢, ä»£ç†åœ°å€, å‚è€ƒå›¾=None):
        
        if genai is None:
            raise ImportError("è¯·å…ˆå®‰è£…å®˜æ–¹åº“: pip install google-genai")

        # è·å–çœŸå® Key
        real_api_key = self.get_api_key(APIå¯†é’¥)
        if not real_api_key:
            raise ValueError("âŒ æœªæ‰¾åˆ° API Keyï¼\nè¯·åœ¨èŠ‚ç‚¹è¾“å…¥æ¡†å¡«å†™ï¼Œæˆ–è€…åœ¨æ’ä»¶ç›®å½•åˆ›å»º api_key.txt æ–‡ä»¶ã€‚")

        print(f"\nğŸŒ å¤§é¦™è•‰ Pro (SDKç‰ˆ) å¯åŠ¨...", flush=True)

        # ä»£ç†è®¾ç½®
        http_options = None
        proxy_url =ä»£ç†åœ°å€.strip()
        if not proxy_url:
            import urllib.request
            sys_proxies = urllib.request.getproxies()
            if "http" in sys_proxies: proxy_url = sys_proxies["http"]
            elif "https" in sys_proxies: proxy_url = sys_proxies["https"]
        
        if proxy_url:
            print(f"ğŸ‘‰ ä½¿ç”¨ä»£ç†: {proxy_url}", flush=True)
            http_options = types.HttpOptions(client_args={"proxy": proxy_url})

        # åˆå§‹åŒ–å®¢æˆ·ç«¯
        client = genai.Client(api_key=real_api_key, http_options=http_options)

        # æ„å»ºå†…å®¹
        contents = [types.Content(parts=[types.Part(text=æç¤ºè¯)])]
        if å‚è€ƒå›¾ is not None:
            print(f"ğŸ“¥ æ·»åŠ å‚è€ƒå›¾: {å‚è€ƒå›¾.shape[0]} å¼ ", flush=True)
            for idx in range(å‚è€ƒå›¾.shape[0]):
                img_bytes = self.tensor_to_bytes(å‚è€ƒå›¾[idx])
                contents[0].parts.append(types.Part.from_bytes(data=img_bytes, mime_type="image/jpeg"))

        # å·¥å…·é…ç½®
        tools = []
        if å¯ç”¨Googleæœç´¢:
            tools.append(types.Tool(google_search=types.GoogleSearch()))
            print("ğŸŒ Google æœç´¢: ON", flush=True)

        image_config = {"image_size": ç”»è´¨ç­‰çº§}
        if "Free" not in é•¿å®½æ¯”:
            image_config["aspect_ratio"] = é•¿å®½æ¯”

        config = types.GenerateContentConfig(
            temperature=1.0,
            tools=tools,
            response_modalities=["IMAGE"], 
            image_config=image_config
        )

        print(f"ğŸš€ è¯·æ±‚æ¨¡å‹: {æ¨¡å‹åç§°} ...", flush=True)
        
        try:
            response = client.models.generate_content(
                model=æ¨¡å‹åç§°,
                contents=contents,
                config=config
            )
        except Exception as e:
            raise RuntimeError(f"SDK è¯·æ±‚å¤±è´¥: {e}")

        # è§£æ
        output_images = []
        if not response.candidates:
             raise RuntimeError(f"ç”Ÿæˆå¤±è´¥ï¼Œæ— Candidatesã€‚")

        for candidate in response.candidates:
            if candidate.grounding_metadata:
                 print(f"ğŸ” æœç´¢æ¥æº: {candidate.grounding_metadata.search_entry_point}", flush=True)
            for part in candidate.content.parts:
                if part.inline_data:
                    img = Image.open(io.BytesIO(part.inline_data.data))
                    output_images.append(img)
                elif part.text:
                    print(f"ğŸ’¬ æ¨¡å‹å›å¤: {part.text[:100]}...", flush=True)

        if not output_images:
            raise RuntimeError("æœªè¿”å›å›¾ç‰‡ã€‚")

        output_tensors = []
        for img in output_images:
            img = img.convert("RGB")
            img_np = np.array(img).astype(np.float32) / 255.0
            output_tensors.append(torch.from_numpy(img_np))

        print(f"âœ¨ æˆåŠŸç”Ÿæˆ {len(output_tensors)} å¼ å›¾ç‰‡", flush=True)
        return (torch.stack(output_tensors),)

NODE_CLASS_MAPPINGS = {"BigBananaOfficialNode": BigBananaProNode}
NODE_DISPLAY_NAME_MAPPINGS = {"BigBananaOfficialNode": "å¤§é¦™è•‰Pro (å®˜æ–¹SDKç‰ˆ)"}
__all__ = ["NODE_CLASS_MAPPINGS", "NODE_DISPLAY_NAME_MAPPINGS"]
