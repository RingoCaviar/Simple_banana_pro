import torch
import numpy as np
import io
import os
import sys
from PIL import Image

# å°è¯•å¯¼å…¥å®˜æ–¹åº“
try:
    from google import genai
    from google.genai import types
except ImportError:
    print("\nâŒ ç¼ºå°‘ google-genai åº“ï¼Œè¯·è¿è¡Œ pip install google-genai\n")
    genai = None
    types = None

# ==========================================
# æ ¸å¿ƒèŠ‚ç‚¹ç±»ï¼šå¤§é¦™è•‰Pro (æ¬ºéª—ç§å­ç‰ˆ)
# ==========================================
class BigBananaProNode:
    def __init__(self):
        self.current_dir = os.path.dirname(os.path.abspath(__file__))

    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "APIå¯†é’¥": ("STRING", {"multiline": False, "default": "", "placeholder": "ç•™ç©ºåˆ™è‡ªåŠ¨è¯»å– api_key.txt"}),
                
                "æç¤ºè¯": ("STRING", {"multiline": True, "dynamicPrompts": True, "default": "A futuristic city with flying cars, cinematic lighting, 4k, masterpiece"}),
                
                "æ¨¡å‹åç§°": ("STRING", {"multiline": False, "default": "gemini-3-pro-image-preview"}),
                
                "ç”»è´¨ç­‰çº§": (["1K", "2K", "4K"], {"default": "1K"}),
                "é•¿å®½æ¯”": (["1:1", "16:9", "9:16", "4:3", "3:4", "21:9", "5:4", "4:5", "æœªæŒ‡å®š(Free)"], {"default": "1:1"}),
                
                "å¯ç”¨Googleæœç´¢": ("BOOLEAN", {"default": False, "label_on": "å¼€å¯ (Grounding)", "label_off": "å…³é—­"}),
                
                # ğŸ”¥ æ–°å¢ï¼šç§å­ (ä»…ç”¨äºè§¦å‘åˆ·æ–°ï¼Œä¸ä¼ ç»™API)
                "seed": ("INT", {"default": 0, "min": 0, "max": 0xffffffffffffffff}),
                
                "ä»£ç†åœ°å€": ("STRING", {"multiline": False, "default": "", "placeholder": "ä¾‹å¦‚ http://127.0.0.1:7890 (ç•™ç©ºè‡ªåŠ¨)"}),
            },
            "optional": {
                "å‚è€ƒå›¾": ("IMAGE",),
            }
        }

    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("å›¾åƒ",)
    FUNCTION = "generate_image"
    CATEGORY = "Banana"

    def tensor_to_bytes(self, img_tensor):
        i = 255. * img_tensor.cpu().numpy()
        img_pil = Image.fromarray(np.clip(i, 0, 255).astype(np.uint8))
        buffered = io.BytesIO()
        img_pil.save(buffered, format="JPEG", quality=95) 
        return buffered.getvalue()

    def get_api_key(self, input_key):
        if input_key and input_key.strip():
            return input_key.strip()
        key_file = os.path.join(self.current_dir, "api_key.txt")
        if os.path.exists(key_file):
            try:
                with open(key_file, "r", encoding="utf-8") as f:
                    file_key = f.read().strip()
                    if file_key:
                        print("ğŸ”‘ å·²ä» api_key.txt è‡ªåŠ¨åŠ è½½å¯†é’¥", flush=True)
                        return file_key
            except Exception as e:
                print(f"âš ï¸ è¯»å– api_key.txt å¤±è´¥: {e}", flush=True)
        return None

    # æ³¨æ„ï¼šè¿™é‡Œå¢åŠ äº† seed å‚æ•°ï¼Œä½†æˆ‘ä»¬åœ¨å‡½æ•°å†…éƒ¨å®Œå…¨ä¸ä½¿ç”¨å®ƒ
    def generate_image(self, APIå¯†é’¥, æç¤ºè¯, æ¨¡å‹åç§°, ç”»è´¨ç­‰çº§, é•¿å®½æ¯”, å¯ç”¨Googleæœç´¢, seed, ä»£ç†åœ°å€, å‚è€ƒå›¾=None):
        
        if genai is None:
            raise ImportError("è¯·å…ˆå®‰è£…å®˜æ–¹åº“: pip install google-genai")

        # è·å–çœŸå® Key
        real_api_key = self.get_api_key(APIå¯†é’¥)
        if not real_api_key:
            raise ValueError("âŒ æœªæ‰¾åˆ° API Keyï¼\nè¯·åœ¨èŠ‚ç‚¹è¾“å…¥æ¡†å¡«å†™ï¼Œæˆ–è€…åœ¨æ’ä»¶ç›®å½•åˆ›å»º api_key.txt æ–‡ä»¶ã€‚")

        # è¿™é‡Œæ‰“å°ä¸€ä¸‹ seedï¼Œè¯æ˜ ComfyUI ç¡®å®æ£€æµ‹åˆ°äº†å˜åŒ–
        print(f"\nğŸŒ å¤§é¦™è•‰ Pro å¯åŠ¨... (ä¼ªè£…ç§å­å·²å˜: {seed})", flush=True)

        # ä»£ç†è®¾ç½®
        http_options = None
        proxy_url =ä»£ç†åœ°å€.strip()
        if not proxy_url:
            import urllib.request
            sys_proxies = urllib.request.getproxies()
            if "http" in sys_proxies: proxy_url = sys_proxies["http"]
            elif "https" in sys_proxies: proxy_url = sys_proxies["https"]
        
        if proxy_url:
            print(f"ğŸ‘‰ ä½¿ç”¨ä»£ç†: {proxy_url}", flush=True)
            http_options = types.HttpOptions(client_args={"proxy": proxy_url})

        # åˆå§‹åŒ–å®¢æˆ·ç«¯
        client = genai.Client(api_key=real_api_key, http_options=http_options)

        # æ„å»ºå†…å®¹
        contents = [types.Content(parts=[types.Part(text=æç¤ºè¯)])]
        if å‚è€ƒå›¾ is not None:
            print(f"ğŸ“¥ æ·»åŠ å‚è€ƒå›¾: {å‚è€ƒå›¾.shape[0]} å¼ ", flush=True)
            for idx in range(å‚è€ƒå›¾.shape[0]):
                img_bytes = self.tensor_to_bytes(å‚è€ƒå›¾[idx])
                contents[0].parts.append(types.Part.from_bytes(data=img_bytes, mime_type="image/jpeg"))

        # å·¥å…·é…ç½®
        tools = []
        if å¯ç”¨Googleæœç´¢:
            tools.append(types.Tool(google_search=types.GoogleSearch()))
            print("ğŸŒ Google æœç´¢: ON", flush=True)

        image_config = {"image_size": ç”»è´¨ç­‰çº§}
        if "Free" not in é•¿å®½æ¯”:
            image_config["aspect_ratio"] = é•¿å®½æ¯”

        # ç”Ÿæˆé…ç½®
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬æ•…æ„æ²¡æœ‰æŠŠ seed ä¼ è¿›å»ï¼Œä¹Ÿæ²¡æœ‰ä¼  temperature ç­‰
        # ä»…ä»…ä¾é  API é»˜è®¤çš„éšæœºæ€§ã€‚
        # ä½†å› ä¸º ComfyUI çœ‹åˆ°è¾“å…¥é‡Œçš„ seed å˜äº†ï¼Œæ‰€ä»¥ä¼šé‡æ–°æ‰§è¡Œåˆ°è¿™é‡Œã€‚
        config = types.GenerateContentConfig(
            temperature=1.0, 
            tools=tools,
            response_modalities=["IMAGE"], 
            image_config=image_config
        )

        print(f"ğŸš€ è¯·æ±‚æ¨¡å‹: {æ¨¡å‹åç§°} ...", flush=True)
        
        try:
            response = client.models.generate_content(
                model=æ¨¡å‹åç§°,
                contents=contents,
                config=config
            )
        except Exception as e:
            raise RuntimeError(f"SDK è¯·æ±‚å¤±è´¥: {e}")

        # è§£æ
        output_images = []
        if not response.candidates:
             raise RuntimeError(f"ç”Ÿæˆå¤±è´¥ï¼Œæ— Candidatesã€‚")

        for candidate in response.candidates:
            if candidate.grounding_metadata:
                 print(f"ğŸ” æœç´¢æ¥æº: {candidate.grounding_metadata.search_entry_point}", flush=True)
            for part in candidate.content.parts:
                if part.inline_data:
                    img = Image.open(io.BytesIO(part.inline_data.data))
                    output_images.append(img)
                elif part.text:
                    print(f"ğŸ’¬ æ¨¡å‹å›å¤: {part.text[:100]}...", flush=True)

        if not output_images:
            raise RuntimeError("æœªè¿”å›å›¾ç‰‡ã€‚")

        output_tensors = []
        for img in output_images:
            img = img.convert("RGB")
            img_np = np.array(img).astype(np.float32) / 255.0
            output_tensors.append(torch.from_numpy(img_np))

        print(f"âœ¨ æˆåŠŸç”Ÿæˆ {len(output_tensors)} å¼ å›¾ç‰‡", flush=True)
        return (torch.stack(output_tensors),)

NODE_CLASS_MAPPINGS = {"BigBananaOfficialNode": BigBananaProNode}
NODE_DISPLAY_NAME_MAPPINGS = {"BigBananaOfficialNode": "å¤§é¦™è•‰Pro (å®˜æ–¹SDKç‰ˆ)"}
__all__ = ["NODE_CLASS_MAPPINGS", "NODE_DISPLAY_NAME_MAPPINGS"]
